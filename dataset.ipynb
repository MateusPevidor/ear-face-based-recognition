{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5Nh8FSC1CKb"
      },
      "outputs": [],
      "source": [
        "base_images_dir = \"/content/drive/My Drive/faces_fei_2/\"\n",
        "base_images_dir_ear = \"/content/drive/My Drive/ears/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVMk6-z4z7dZ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "#from tensorflow.keras.applications.vggface import VGGFace\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.utils import load_img, save_img, img_to_array, to_categorical\n",
        "\n",
        "from keras.optimizers.optimizer_v1 import Optimizer\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, GlobalAveragePooling2D"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0l-S1Wk0dyJ",
        "outputId": "feb80f30-4d20-4821-cacc-452c7941c28f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQKBRQAw0QgR"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "  img = load_img(image_path, target_size=(224, 224))\n",
        "  img = img_to_array(img)\n",
        "  img = preprocess_input(img)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGv3mS3B3Th5"
      },
      "source": [
        "# Face Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d45ZoX3u0bSA",
        "outputId": "a45c3983-0826-47af-926a-d048a980758c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 10, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 11, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 12, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 13, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 14, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 15, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 16, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 17, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 18, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 19, 1, 200, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 2, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 3, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 4, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 5, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 6, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 7, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 8, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 9]\n",
            "100\n",
            "(1, 's1_04.jpg', 's1_05.jpg', 's1_06.jpg', 's1_07.jpg', 's1_11.jpg')\n",
            "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n"
          ]
        }
      ],
      "source": [
        "from os import listdir\n",
        "import re\n",
        "\n",
        "faces = listdir(base_images_dir)\n",
        "faces_1 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_04.jpg').match(s)])\n",
        "faces_2 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_05.jpg').match(s)])\n",
        "faces_3 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_06.jpg').match(s)])\n",
        "faces_4 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_07.jpg').match(s)])\n",
        "faces_5 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_11.jpg').match(s)])\n",
        "#faces_6 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_06.jpg').match(s)])\n",
        "#faces_7 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_07.jpg').match(s)])\n",
        "#faces_8 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_08.jpg').match(s)])\n",
        "#faces_9 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_09.jpg').match(s)])\n",
        "#faces_10 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_10.jpg').match(s)])\n",
        "#faces_11 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_11.jpg').match(s)])\n",
        "#faces_12 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_12.jpg').match(s)])\n",
        "#faces_13 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_13.jpg').match(s)])\n",
        "#faces_14 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_14.jpg').match(s)])\n",
        "#faces_15 = sorted([s for s in faces if re.compile('s\\d?\\d?\\d_15.jpg').match(s)])\n",
        "ids_ears = [int(s.replace(\"s\", \"\").split(\"_\")[0]) for s in faces_1]\n",
        "subjects = list(zip(ids_ears, faces_1, faces_2, faces_3, faces_4, faces_5))#, faces_6, faces_7,faces_8,faces_9,faces_10,faces_11,faces_12,faces_13,faces_14,faces_15))\n",
        "subjects = sorted(subjects, key=lambda x: x[0])[:100]\n",
        "print(ids_ears)\n",
        "print(len(subjects))\n",
        "print(subjects[0])\n",
        "print([s[0] for s in subjects])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rD9ej5Sa1Op-"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for subject in subjects:\n",
        "  ids_ear, faces_1, faces_2, faces_3, faces_4, faces_5 = subject#, faces_6, faces_7,faces_8,faces_9,faces_10,faces_11,faces_12,faces_13,faces_14,faces_15 = subject\n",
        "  ids_ear = ids_ear - 1\n",
        "  faces_1 = preprocess_image(f'{base_images_dir}{faces_1}')\n",
        "  faces_2 = preprocess_image(f'{base_images_dir}{faces_2}')\n",
        "  faces_3 = preprocess_image(f'{base_images_dir}{faces_3}')\n",
        "  faces_4 = preprocess_image(f'{base_images_dir}{faces_4}')\n",
        "  faces_5 = preprocess_image(f'{base_images_dir}{faces_5}')\n",
        "  #faces_6 = preprocess_image(f'{base_images_dir}{faces_6}')\n",
        "  #faces_7 = preprocess_image(f'{base_images_dir}{faces_7}')\n",
        "  #faces_8 = preprocess_image(f'{base_images_dir}{faces_8}')\n",
        "  #faces_9 = preprocess_image(f'{base_images_dir}{faces_9}')\n",
        "  #faces_10 = preprocess_image(f'{base_images_dir}{faces_10}')\n",
        "  #faces_11 = preprocess_image(f'{base_images_dir}{faces_11}')\n",
        "  #faces_12 = preprocess_image(f'{base_images_dir}{faces_12}')\n",
        "  #faces_13 = preprocess_image(f'{base_images_dir}{faces_13}')\n",
        "  #faces_14 = preprocess_image(f'{base_images_dir}{faces_14}')\n",
        "  #faces_15 = preprocess_image(f'{base_images_dir}{faces_15}')\n",
        "  labels = [ids_ear] * 5\n",
        "\n",
        "  X_train.append(faces_1)\n",
        "  X_train.append(faces_2)\n",
        "  X_train.append(faces_3)\n",
        "  X_train.append(faces_4)\n",
        "  X_train.append(faces_5)\n",
        "  #X_train.append(faces_6)\n",
        "  #X_train.append(faces_7)\n",
        "  #X_train.append(faces_8)\n",
        "  #X_train.append(faces_9)\n",
        "  #X_train.append(faces_10)\n",
        "  #X_train.append(faces_11)\n",
        "  #X_train.append(faces_12)\n",
        "  #X_train.append(faces_13)\n",
        "  #X_train.append(faces_14)\n",
        "  #X_train.append(faces_15)\n",
        "\n",
        "  y_train.extend(labels)\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2koTJCG1d7w"
      },
      "outputs": [],
      "source": [
        "def loadVggFaceModel():\n",
        "  model = Sequential()\n",
        "  model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(2622, (1, 1)))\n",
        "  \n",
        "  model.add(GlobalAveragePooling2D())\n",
        "  model.add(Dense(128, activation='relu'))\n",
        "  model.add(Dense(100, activation='softmax'))\n",
        "\n",
        "  model.load_weights('/content/drive/MyDrive/trained_weights_face_2023_03_02_04_51_58.h5')\n",
        "\n",
        "  return model\n",
        "\n",
        "model = loadVggFaceModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FABeZAAp2U8B",
        "outputId": "499a84f0-7d31-49ed-c6f4-63ee0bded5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 350s 22s/step\n"
          ]
        }
      ],
      "source": [
        "prediction = model.predict(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1D1TVoYS3WLc"
      },
      "source": [
        "# Ear Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UrkzHsG3YDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76bd8f6-3214-4e81-8952-66ee31a88918"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "from os import listdir\n",
        "import re\n",
        "\n",
        "ears = listdir(base_images_dir_ear)\n",
        "front_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_front_ear.jpg').match(s)])\n",
        "back_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_back_ear.jpg').match(s)])\n",
        "left_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_left_ear.jpg').match(s)])\n",
        "right_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_right_ear.jpg').match(s)])\n",
        "up_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_front_ear.jpg').match(s)])\n",
        "zoom_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_zoom_ear.jpg').match(s)])\n",
        "down_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_down_ear.jpg').match(s)])\n",
        "ids_ears = [int(s[:3]) for s in front_ears]\n",
        "\n",
        "subjects = list(zip(ids_ears, front_ears, back_ears, left_ears, right_ears, up_ears, zoom_ears, down_ears))\n",
        "len(subjects)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for subject in subjects:\n",
        "  ids_ear, front_ear, back_ear, left_ear, right_ear, up_ear, zoom_ear, down_ear = subject\n",
        "  front_ear = preprocess_image(f'{base_images_dir_ear}{front_ear}')\n",
        "  back_ear = preprocess_image(f'{base_images_dir_ear}{back_ear}')\n",
        "  left_ear = preprocess_image(f'{base_images_dir_ear}{left_ear}')\n",
        "  right_ear = preprocess_image(f'{base_images_dir_ear}{right_ear}')\n",
        "  up_ear = preprocess_image(f'{base_images_dir_ear}{up_ear}')\n",
        "  zoom_ear = preprocess_image(f'{base_images_dir_ear}{zoom_ear}')\n",
        "  down_ear = preprocess_image(f'{base_images_dir_ear}{down_ear}')\n",
        "  labels = [ids_ear] * 7\n",
        "\n",
        "  X_train.append(front_ear)\n",
        "  X_train.append(back_ear)\n",
        "  X_train.append(left_ear)\n",
        "  X_train.append(right_ear)\n",
        "  X_train.append(up_ear)\n",
        "  X_train.append(zoom_ear)\n",
        "  X_train.append(down_ear)\n",
        "\n",
        "  y_train.extend(labels)\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "metadata": {
        "id": "H9O5qH1z7q06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadVggFaceModel_ear():\n",
        "  model = Sequential()\n",
        "  model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(2622, (1, 1)))\n",
        "\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "\n",
        "  # model.add(Dense(40, activation='relu'))\n",
        "  model.add(Dense(107, activation='softmax'))\n",
        "\n",
        "  model.load_weights('/content/drive/MyDrive/trained_weights_2022_10_18_15_28_37.h5')\n",
        "\n",
        "  return model\n",
        "\n",
        "model_ear = loadVggFaceModel_ear()"
      ],
      "metadata": {
        "id": "oEmEsWJ97zHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction_ear = model_ear.predict(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GDS2Wka8OIu",
        "outputId": "915fa21b-f015-45b0-f804-dfb021a98c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 472s 21s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_prediction_ear = []\n",
        "filtered_label_ear = []\n",
        "for i, p in enumerate(prediction_ear):\n",
        "  if i % 6 != 0 and i % 7 != 0:\n",
        "    filtered_prediction_ear.append(p[0][0])\n",
        "    filtered_label_ear.append(y_train[i])\n",
        "print(filtered_prediction_ear[0])\n",
        "print(filtered_label_ear[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtK0Lj6-DDJp",
        "outputId": "f6103990-f37e-4e04-9345-f29972f3806c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9.9574822e-01 6.0309613e-10 9.2946834e-08 1.0393298e-06 1.1262311e-13\n",
            " 7.8404901e-06 3.7377314e-13 2.4048859e-06 8.2659490e-06 2.6008895e-06\n",
            " 1.8720982e-08 3.5485581e-10 2.4899007e-08 3.3611767e-09 2.8401317e-07\n",
            " 4.0798104e-10 1.0042006e-09 1.9177917e-12 1.5035875e-12 9.6011916e-14\n",
            " 1.8290889e-04 7.8960863e-04 3.8059647e-14 8.8127377e-04 1.7966520e-10\n",
            " 9.7591354e-08 8.3442764e-09 4.2782020e-16 1.0846509e-09 3.0137540e-10\n",
            " 1.3449749e-04 1.7846716e-09 1.5049647e-12 8.6192187e-10 7.8545192e-05\n",
            " 8.9862251e-10 1.2591579e-04 5.6561071e-13 1.8157932e-04 1.7339784e-07\n",
            " 4.7115382e-08 9.4877269e-06 4.5815050e-05 8.4697081e-07 8.3530217e-08\n",
            " 1.2256382e-06 1.1805572e-09 1.0388834e-05 2.4373740e-05 8.5105673e-10\n",
            " 3.0356204e-09 9.2148788e-08 1.1436091e-09 5.5041874e-06 4.7029057e-06\n",
            " 8.4705951e-11 1.1988514e-08 3.9068592e-08 5.4229184e-11 1.2112395e-07\n",
            " 8.9113196e-12 1.9003069e-08 1.9599787e-08 8.8228117e-04 4.9662876e-06\n",
            " 2.2946901e-06 1.2683878e-09 7.6103097e-06 4.9834688e-07 1.3945594e-12\n",
            " 3.5263032e-08 9.6040886e-10 4.5021378e-09 3.5472181e-10 3.3930439e-04\n",
            " 2.8459477e-05 1.8857019e-08 6.8216559e-13 2.2597006e-04 6.1375394e-09\n",
            " 2.6177694e-11 1.0559999e-10 5.7728144e-13 1.7983226e-09 3.0884308e-07\n",
            " 6.5411612e-08 1.9878833e-05 1.2298895e-08 9.2839719e-10 1.3341587e-09\n",
            " 1.6832179e-13 1.5609976e-13 1.8803588e-05 2.4702956e-06 2.2029253e-10\n",
            " 1.4100149e-10 2.9528262e-06 5.3438764e-11 6.8810832e-11 9.7776465e-10\n",
            " 1.7818336e-07 3.8697755e-07 2.1540388e-04 6.2638938e-09 9.1529283e-14\n",
            " 3.9887338e-09 4.9443574e-09]\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "concated = []\n",
        "for i in range(len(prediction)):\n",
        "  concated.append(np.concatenate((prediction[i], filtered_prediction_ear[i])))\n",
        "\n"
      ],
      "metadata": {
        "id": "5Uq6DmVbG1xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np_concated = np.array(concated)"
      ],
      "metadata": {
        "id": "uaG8TVNvImxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.savetxt(\"concated.txt\", np_concated)"
      ],
      "metadata": {
        "id": "oDe3EunRJILk"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}