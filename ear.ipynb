{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "ears_base_dir = \"/content/drive/My Drive/ears/ears/\""
      ],
      "metadata": {
        "id": "Cl-klT-OWF2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpyHZvygFWC0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from sklearn.metrics import plot_confusion_matrix, accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.applications.imagenet_utils import preprocess_input\n",
        "from tensorflow.keras.utils import load_img, save_img, img_to_array, to_categorical\n",
        "\n",
        "from keras.optimizers.optimizer_v1 import Optimizer\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Input, Convolution2D, ZeroPadding2D, MaxPooling2D, Flatten, Dense, Dropout, Activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgqOC4UfJjEt"
      },
      "source": [
        "# Data download"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zzQ64S0Fodg"
      },
      "outputs": [],
      "source": [
        "# !gdown 1CPSeum3HpopfomUEK1gybeuIVoeJT_Eo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ORE0CyskIcp1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "334cf53a-7c17-4adc-e57e-e0df42d9a334"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzutTzBuI6Hb"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/My Drive/ears/ears\" \"ears/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/drive/My Drive/vgg_face_weights.h5\" \"./vgg_face_weights.h5\""
      ],
      "metadata": {
        "id": "IcgOuKnwihH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp \"/content/drive/My Drive/trained_weights_2022_10_14_19_04_48.h5\" \"./trained_weights_2022_10_14_19_04_48.h5\""
      ],
      "metadata": {
        "id": "Tpd_S9tQlcos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khk7xNI1Jm6S"
      },
      "source": [
        "# Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KK3YjEm6RjGT"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image_path):\n",
        "  img = load_img(image_path, target_size=(224, 224))\n",
        "  img = img_to_array(img)\n",
        "  # img = np.expand_dims(img, axis=0)\n",
        "  \n",
        "  #preprocess_input normalizes input in scale of [-1, +1]. You must apply same normalization in prediction.\n",
        "  #Ref: https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py (Line 45)\n",
        "  img = preprocess_input(img)\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomTranslation(0.1, 0.1)\n",
        "])"
      ],
      "metadata": {
        "id": "ubfzFXu-jE7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJ7-a75SJokk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf798f51-4741-45f7-ad6a-846dee5cbd4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "from os import listdir\n",
        "import re\n",
        "\n",
        "ears = listdir(ears_base_dir)\n",
        "front_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_front_ear.jpg').match(s)])\n",
        "back_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_back_ear.jpg').match(s)])\n",
        "left_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_left_ear.jpg').match(s)])\n",
        "right_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_right_ear.jpg').match(s)])\n",
        "up_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_front_ear.jpg').match(s)])\n",
        "zoom_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_zoom_ear.jpg').match(s)])\n",
        "down_ears = sorted([s for s in ears if re.compile('\\d\\d\\d_down_ear.jpg').match(s)])\n",
        "ids_ears = [int(s[:3]) for s in front_ears]\n",
        "\n",
        "subjects = list(zip(ids_ears, front_ears, back_ears, left_ears, right_ears, up_ears, zoom_ears, down_ears))\n",
        "len(subjects)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = list()\n",
        "y_train = list()"
      ],
      "metadata": {
        "id": "ZiBxdwG1gjg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIxxmNvqQmQf"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for subject in subjects:\n",
        "  ids_ear, front_ear, back_ear, left_ear, right_ear, up_ear, zoom_ear, down_ear = subject\n",
        "  front_ear = preprocess_image(f'{ears_base_dir}{front_ear}')\n",
        "  back_ear = preprocess_image(f'{ears_base_dir}{back_ear}')\n",
        "  left_ear = preprocess_image(f'{ears_base_dir}{left_ear}')\n",
        "  right_ear = preprocess_image(f'{ears_base_dir}{right_ear}')\n",
        "  up_ear = preprocess_image(f'{ears_base_dir}{up_ear}')\n",
        "  zoom_ear = preprocess_image(f'{ears_base_dir}{zoom_ear}')\n",
        "  down_ear = preprocess_image(f'{ears_base_dir}{down_ear}')\n",
        "  labels = [ids_ear] * 7\n",
        "\n",
        "  X_train.append(front_ear)\n",
        "  X_train.append(back_ear)\n",
        "  X_train.append(left_ear)\n",
        "  X_train.append(right_ear)\n",
        "  X_train.append(up_ear)\n",
        "  X_train.append(zoom_ear)\n",
        "  X_train.append(down_ear)\n",
        "\n",
        "  augmentation_rounds = 1\n",
        "  for i in range(augmentation_rounds):\n",
        "    front_ear_augmented = data_augmentation(front_ear, training=True)\n",
        "    back_ear_augmented = data_augmentation(back_ear, training=True)\n",
        "    left_ear_augmented = data_augmentation(left_ear, training=True)\n",
        "    right_ear_augmented = data_augmentation(right_ear, training=True)\n",
        "    up_ear_augmented = data_augmentation(up_ear, training=True)\n",
        "    down_ear_augmented = data_augmentation(down_ear, training=True)\n",
        "\n",
        "    X_train.append(front_ear_augmented)\n",
        "    X_train.append(back_ear_augmented)\n",
        "    X_train.append(left_ear_augmented)\n",
        "    X_train.append(right_ear_augmented)\n",
        "    X_train.append(up_ear_augmented)\n",
        "    X_train.append(down_ear_augmented)\n",
        "\n",
        "    labels.extend([ids_ear] * 6)\n",
        "\n",
        "    \n",
        "\n",
        "  y_train.extend(labels)\n",
        "\n",
        "  #X_train = np.asarray(X_train)\n",
        "  #y_train = np.asarray(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.asarray(X_train)\n",
        "y_train = np.asarray(y_train)"
      ],
      "metadata": {
        "id": "DiwPwylug5IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_train[0])"
      ],
      "metadata": {
        "id": "MTjTZSPTirnq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN9waodQUAAn"
      },
      "outputs": [],
      "source": [
        "# X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QThwqMcgU9-i"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_train, y_train, test_size=0.15, shuffle=True)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.15, shuffle=True)\n",
        "\n",
        "X_train = np.asarray(X_train)\n",
        "X_test = np.asarray(X_test)\n",
        "X_val = np.asarray(X_val)\n",
        "y_train = np.asarray(y_train)\n",
        "y_test = np.asarray(y_test)\n",
        "y_val = np.asarray(y_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assume X_train and y_train are the training data\n",
        "n = X_train.shape[0]  # total number of samples\n",
        "indices = np.random.permutation(n)  # shuffle the indices\n",
        "\n",
        "# set the sizes of the train, validation, and test sets (e.g., 60%, 20%, 20%)\n",
        "train_size = int(0.6 * n)\n",
        "val_size = int(0.2 * n)\n",
        "\n",
        "# split the indices into train, validation, and test sets\n",
        "train_indices = indices[:train_size]\n",
        "val_indices = indices[train_size:train_size+val_size]\n",
        "test_indices = indices[train_size+val_size:]\n",
        "\n",
        "# get the actual data based on the indices\n",
        "X_train_split = X_train[train_indices]\n",
        "y_train_split = y_train[train_indices]\n",
        "X_val_split = X_train[val_indices]\n",
        "y_val_split = y_train[val_indices]\n",
        "X_test = X_train[test_indices]\n",
        "y_test = y_train[test_indices]"
      ],
      "metadata": {
        "id": "NKk-hGPngYGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "amS4BaQIi1sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJC7Ui1fLlUe"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_F3qrL2HM9H"
      },
      "outputs": [],
      "source": [
        "def loadVggFaceModel():\n",
        "  model = Sequential()\n",
        "  model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(ZeroPadding2D((1,1)))\n",
        "  model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
        "\n",
        "  model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Convolution2D(2622, (1, 1)))\n",
        "  model.load_weights(\"/content/drive/My Drive/vgg_face_weights.h5\")\n",
        "\n",
        "  for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "  \n",
        "  #model.add(Dense(256, activation='relu'))\n",
        " # model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dense(40, activation='relu'))\n",
        "  model.add(Dense(107, activation='softmax'))\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URdBl0uzO5wE"
      },
      "outputs": [],
      "source": [
        "model = loadVggFaceModel()\n",
        "# model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqcrEsNMU5S7"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XmcsayEUDQ8"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.01),\n",
        "    metrics=['sparse_categorical_accuracy', 'accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 30:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)\n",
        "\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)"
      ],
      "metadata": {
        "id": "t_4uo5DBynSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import Callback\n",
        "\n",
        "class MyCallback(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        model = self.model\n",
        "        #test_generator.reset()\n",
        "        pred = model.predict(X_test)\n",
        "        pred_train = model.predict(X_train)\n",
        "        predicted_test = [np.argmax(x) for x in pred]\n",
        "        predicted_train = [np.argmax(x) for x in pred_train]\n",
        "        accuracy_test = accuracy_score(predicted_test, y_test)\n",
        "        accuracy_train = accuracy_score(predicted_train, y_train)\n",
        "        print('Test Accuracy:', accuracy_test)\n",
        "        print('Train Accuracy:', accuracy_train)\n",
        "        print(predicted_test)\n",
        "\n",
        "my_callback = MyCallback()"
      ],
      "metadata": {
        "id": "pO1sTLRCWq37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VaVG8zmUst5"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=80, batch_size=8, callbacks=[callback, my_callback], validation_data=(X_val, y_val))\n",
        "# model.load_weights('./trained_weights_2022_10_14_19_04_48.h5')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "now = datetime.now()\n",
        "timestamp = now.strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
        "# model.save_weights(f'./trained_weights_{timestamp}.h5')"
      ],
      "metadata": {
        "id": "0ZINiZe3t3u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyegpI7ofDWU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a61e1a8-de09-4384-9142-39ce8835375f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 10s 407ms/step\n",
            "4/4 [==============================] - 2s 685ms/step\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "pred_train = model.predict(X_train)\n",
        "pred_test = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvX_qzEJfYQJ"
      },
      "outputs": [],
      "source": [
        "predicted_train = [np.argmax(x[0][0]) for x in pred_train]\n",
        "predicted_test = [np.argmax(x[0][0]) for x in pred_test]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc = accuracy_score(y_train, predicted_train)\n",
        "test_acc = accuracy_score(y_test, predicted_test)\n",
        "\n",
        "print(f'Train accuracy: {train_acc}')\n",
        "print(f'Test accuracy: {test_acc}')"
      ],
      "metadata": {
        "id": "6PXslt5dxpam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f71e8b45-d9ea-4c21-dc41-02fa8bb6ea8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy: 0.500990099009901\n",
            "Test accuracy: 0.2857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def true_positive(y_true, y_pred):\n",
        "    \n",
        "    tp = 0\n",
        "    \n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        \n",
        "        if yt == 1 and yp == 1:\n",
        "            tp += 1\n",
        "    \n",
        "    return tp\n",
        "\n",
        "def true_negative(y_true, y_pred):\n",
        "    \n",
        "    tn = 0\n",
        "    \n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        \n",
        "        if yt == 0 and yp == 0:\n",
        "            tn += 1\n",
        "            \n",
        "    return tn\n",
        "\n",
        "def false_positive(y_true, y_pred):\n",
        "    \n",
        "    fp = 0\n",
        "    \n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        \n",
        "        if yt == 0 and yp == 1:\n",
        "            fp += 1\n",
        "            \n",
        "    return fp\n",
        "\n",
        "def false_negative(y_true, y_pred):\n",
        "    \n",
        "    fn = 0\n",
        "    \n",
        "    for yt, yp in zip(y_true, y_pred):\n",
        "        \n",
        "        if yt == 1 and yp == 0:\n",
        "            fn += 1\n",
        "            \n",
        "    return fn\n",
        "\n",
        "def macro_precision(y_true, y_pred):\n",
        "\n",
        "    # find the number of classes\n",
        "    num_classes = len(np.unique(y_true))\n",
        "\n",
        "    # initialize precision to 0\n",
        "    precision = 0\n",
        "    \n",
        "    # loop over all classes\n",
        "    for class_ in list(np.unique(y_true)):\n",
        "        \n",
        "        # all classes except current are considered negative\n",
        "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
        "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
        "        \n",
        "        \n",
        "        # compute true positive for current class\n",
        "        tp = true_positive(temp_true, temp_pred)\n",
        "        \n",
        "        # compute false positive for current class\n",
        "        fp = false_positive(temp_true, temp_pred)\n",
        "        \n",
        "        \n",
        "        # compute precision for current class\n",
        "        temp_precision = tp / (tp + fp + 1e-6)\n",
        "        # keep adding precision for all classes\n",
        "        precision += temp_precision\n",
        "        \n",
        "    # calculate and return average precision over all classes\n",
        "    precision /= num_classes\n",
        "    \n",
        "    return precision\n",
        "\n",
        "def micro_precision(y_true, y_pred):\n",
        "\n",
        "\n",
        "    # find the number of classes \n",
        "    num_classes = len(np.unique(y_true))\n",
        "    \n",
        "    # initialize tp and fp to 0\n",
        "    tp = 0\n",
        "    fp = 0\n",
        "    \n",
        "    # loop over all classes\n",
        "    for class_ in np.unique(y_true):\n",
        "        \n",
        "        # all classes except current are considered negative\n",
        "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
        "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
        "        \n",
        "        # calculate true positive for current class\n",
        "        # and update overall tp\n",
        "        tp += true_positive(temp_true, temp_pred)\n",
        "        \n",
        "        # calculate false positive for current class\n",
        "        # and update overall tp\n",
        "        fp += false_positive(temp_true, temp_pred)\n",
        "        \n",
        "    # calculate and return overall precision\n",
        "    precision = tp / (tp + fp)\n",
        "    return precision\n",
        "\n",
        "def macro_recall(y_true, y_pred):\n",
        "\n",
        "    # find the number of classes\n",
        "    num_classes = len(np.unique(y_true))\n",
        "\n",
        "    # initialize recall to 0\n",
        "    recall = 0\n",
        "    \n",
        "    # loop over all classes\n",
        "    for class_ in list(np.unique(y_true)):\n",
        "        \n",
        "        # all classes except current are considered negative\n",
        "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
        "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
        "        \n",
        "        \n",
        "        # compute true positive for current class\n",
        "        tp = true_positive(temp_true, temp_pred)\n",
        "        \n",
        "        # compute false negative for current class\n",
        "        fn = false_negative(temp_true, temp_pred)\n",
        "        \n",
        "        \n",
        "        # compute recall for current class\n",
        "        temp_recall = tp / (tp + fn + 1e-6)\n",
        "        \n",
        "        # keep adding recall for all classes\n",
        "        recall += temp_recall\n",
        "        \n",
        "    # calculate and return average recall over all classes\n",
        "    recall /= num_classes\n",
        "    \n",
        "    return recall\n",
        "\n",
        "def micro_recall(y_true, y_pred):\n",
        "\n",
        "\n",
        "    # find the number of classes \n",
        "    num_classes = len(np.unique(y_true))\n",
        "    \n",
        "    # initialize tp and fp to 0\n",
        "    tp = 0\n",
        "    fn = 0\n",
        "    \n",
        "    # loop over all classes\n",
        "    for class_ in np.unique(y_true):\n",
        "        \n",
        "        # all classes except current are considered negative\n",
        "        temp_true = [1 if p == class_ else 0 for p in y_true]\n",
        "        temp_pred = [1 if p == class_ else 0 for p in y_pred]\n",
        "        \n",
        "        # calculate true positive for current class\n",
        "        # and update overall tp\n",
        "        tp += true_positive(temp_true, temp_pred)\n",
        "        \n",
        "        # calculate false negative for current class\n",
        "        # and update overall tp\n",
        "        fn += false_negative(temp_true, temp_pred)\n",
        "        \n",
        "    # calculate and return overall recall\n",
        "    recall = tp / (tp + fn)\n",
        "    return recall"
      ],
      "metadata": {
        "id": "1KeOKO5rpK2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Macro-averaged Precision score : {macro_precision(y_test, predicted_test) }\")\n",
        "# print(f\"Micro-averaged Precision score : {micro_precision(y_test, predicted_test)}\")\n",
        "print(f\"Macro-averaged recall score : {macro_recall(y_test, predicted_test)}\")\n",
        "print(f\"Train accuracy: {train_acc}\")\n",
        "print(f\"Test accuracy: {test_acc}\")\n",
        "\n",
        "# print(f\"Micro-averaged recall score : {micro_recall(y_test, predicted_test)}\")\n"
      ],
      "metadata": {
        "id": "ObM0YNIvmrrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(y_train[:50])\n",
        "# print(predicted_train[:50])"
      ],
      "metadata": {
        "id": "CZRJKwioV4T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp './trained_weights_2022_10_18_15_28_37.h5' '/content/drive/MyDrive'"
      ],
      "metadata": {
        "id": "SNipb8FiFgkQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}